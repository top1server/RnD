{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define the root directory for the dataset\n",
    "ROOT = './data'\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=False,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training : validation = 0.9 : 0.1\n",
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(\n",
    "    train_data,\n",
    "    [n_train_examples, n_valid_examples]\n",
    ")\n",
    "\n",
    "# compute mean and std for normalization\n",
    "mean = train_data.dataset.data.float().mean() / 255\n",
    "std = train_data.dataset.data.float().std() / 255\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "train_data.dataset.transform = train_transforms\n",
    "valid_data.dataset.transform = test_transforms\n",
    "\n",
    "# Create dataloader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding='same')\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.flatten(outputs)\n",
    "        outputs = self.fc_1(outputs)\n",
    "        outputs = self.fc_2(outputs)\n",
    "        outputs = self.fc_3(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, criterion, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  211 batches | accuracy    0.712\n",
      "| epoch   1 |   100/  211 batches | accuracy    0.890\n",
      "| epoch   1 |   150/  211 batches | accuracy    0.920\n",
      "| epoch   1 |   200/  211 batches | accuracy    0.941\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time: 14.97s | Train Accuracy    0.947 | Train Loss    0.473 | Valid Accuracy    0.945 | Valid Loss    0.188\n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    50/  211 batches | accuracy    0.954\n",
      "| epoch   2 |   100/  211 batches | accuracy    0.959\n",
      "| epoch   2 |   150/  211 batches | accuracy    0.963\n",
      "| epoch   2 |   200/  211 batches | accuracy    0.967\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time: 14.92s | Train Accuracy    0.972 | Train Loss    0.129 | Valid Accuracy    0.972 | Valid Loss    0.094\n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    50/  211 batches | accuracy    0.972\n",
      "| epoch   3 |   100/  211 batches | accuracy    0.969\n",
      "| epoch   3 |   150/  211 batches | accuracy    0.974\n",
      "| epoch   3 |   200/  211 batches | accuracy    0.976\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time: 14.92s | Train Accuracy    0.972 | Train Loss    0.089 | Valid Accuracy    0.976 | Valid Loss    0.076\n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    50/  211 batches | accuracy    0.976\n",
      "| epoch   4 |   100/  211 batches | accuracy    0.980\n",
      "| epoch   4 |   150/  211 batches | accuracy    0.976\n",
      "| epoch   4 |   200/  211 batches | accuracy    0.979\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time: 14.77s | Train Accuracy    0.980 | Train Loss    0.074 | Valid Accuracy    0.980 | Valid Loss    0.066\n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    50/  211 batches | accuracy    0.980\n",
      "| epoch   5 |   100/  211 batches | accuracy    0.982\n",
      "| epoch   5 |   150/  211 batches | accuracy    0.979\n",
      "| epoch   5 |   200/  211 batches | accuracy    0.983\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time: 14.86s | Train Accuracy    0.982 | Train Loss    0.063 | Valid Accuracy    0.976 | Valid Loss    0.071\n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    50/  211 batches | accuracy    0.981\n",
      "| epoch   6 |   100/  211 batches | accuracy    0.981\n",
      "| epoch   6 |   150/  211 batches | accuracy    0.983\n",
      "| epoch   6 |   200/  211 batches | accuracy    0.983\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time: 14.89s | Train Accuracy    0.987 | Train Loss    0.057 | Valid Accuracy    0.981 | Valid Loss    0.061\n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    50/  211 batches | accuracy    0.985\n",
      "| epoch   7 |   100/  211 batches | accuracy    0.983\n",
      "| epoch   7 |   150/  211 batches | accuracy    0.984\n",
      "| epoch   7 |   200/  211 batches | accuracy    0.984\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time: 14.88s | Train Accuracy    0.985 | Train Loss    0.051 | Valid Accuracy    0.984 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    50/  211 batches | accuracy    0.987\n",
      "| epoch   8 |   100/  211 batches | accuracy    0.984\n",
      "| epoch   8 |   150/  211 batches | accuracy    0.985\n",
      "| epoch   8 |   200/  211 batches | accuracy    0.984\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time: 14.81s | Train Accuracy    0.986 | Train Loss    0.048 | Valid Accuracy    0.984 | Valid Loss    0.051\n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    50/  211 batches | accuracy    0.986\n",
      "| epoch   9 |   100/  211 batches | accuracy    0.987\n",
      "| epoch   9 |   150/  211 batches | accuracy    0.987\n",
      "| epoch   9 |   200/  211 batches | accuracy    0.987\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time: 14.92s | Train Accuracy    0.982 | Train Loss    0.044 | Valid Accuracy    0.985 | Valid Loss    0.049\n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    50/  211 batches | accuracy    0.988\n",
      "| epoch  10 |   100/  211 batches | accuracy    0.987\n",
      "| epoch  10 |   150/  211 batches | accuracy    0.985\n",
      "| epoch  10 |   200/  211 batches | accuracy    0.986\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time: 14.83s | Train Accuracy    0.988 | Train Loss    0.043 | Valid Accuracy    0.985 | Valid Loss    0.048\n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |    50/  211 batches | accuracy    0.989\n",
      "| epoch  11 |   100/  211 batches | accuracy    0.989\n",
      "| epoch  11 |   150/  211 batches | accuracy    0.987\n",
      "| epoch  11 |   200/  211 batches | accuracy    0.987\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  11 | Time: 14.84s | Train Accuracy    0.986 | Train Loss    0.038 | Valid Accuracy    0.989 | Valid Loss    0.043\n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |    50/  211 batches | accuracy    0.990\n",
      "| epoch  12 |   100/  211 batches | accuracy    0.990\n",
      "| epoch  12 |   150/  211 batches | accuracy    0.989\n",
      "| epoch  12 |   200/  211 batches | accuracy    0.988\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  12 | Time: 15.03s | Train Accuracy    0.983 | Train Loss    0.036 | Valid Accuracy    0.984 | Valid Loss    0.054\n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |    50/  211 batches | accuracy    0.989\n",
      "| epoch  13 |   100/  211 batches | accuracy    0.990\n",
      "| epoch  13 |   150/  211 batches | accuracy    0.989\n",
      "| epoch  13 |   200/  211 batches | accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  13 | Time: 14.93s | Train Accuracy    0.985 | Train Loss    0.035 | Valid Accuracy    0.985 | Valid Loss    0.049\n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |    50/  211 batches | accuracy    0.990\n",
      "| epoch  14 |   100/  211 batches | accuracy    0.991\n",
      "| epoch  14 |   150/  211 batches | accuracy    0.989\n",
      "| epoch  14 |   200/  211 batches | accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  14 | Time: 14.71s | Train Accuracy    0.991 | Train Loss    0.032 | Valid Accuracy    0.986 | Valid Loss    0.049\n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  15 |   100/  211 batches | accuracy    0.990\n",
      "| epoch  15 |   150/  211 batches | accuracy    0.987\n",
      "| epoch  15 |   200/  211 batches | accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  15 | Time: 15.23s | Train Accuracy    0.987 | Train Loss    0.032 | Valid Accuracy    0.985 | Valid Loss    0.052\n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |    50/  211 batches | accuracy    0.990\n",
      "| epoch  16 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  16 |   150/  211 batches | accuracy    0.990\n",
      "| epoch  16 |   200/  211 batches | accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  16 | Time: 15.27s | Train Accuracy    0.993 | Train Loss    0.030 | Valid Accuracy    0.989 | Valid Loss    0.037\n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  17 |   100/  211 batches | accuracy    0.991\n",
      "| epoch  17 |   150/  211 batches | accuracy    0.990\n",
      "| epoch  17 |   200/  211 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  17 | Time: 13.18s | Train Accuracy    0.988 | Train Loss    0.028 | Valid Accuracy    0.988 | Valid Loss    0.044\n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  18 |   100/  211 batches | accuracy    0.993\n",
      "| epoch  18 |   150/  211 batches | accuracy    0.992\n",
      "| epoch  18 |   200/  211 batches | accuracy    0.989\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  18 | Time:  7.88s | Train Accuracy    0.991 | Train Loss    0.026 | Valid Accuracy    0.986 | Valid Loss    0.049\n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  19 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  19 |   150/  211 batches | accuracy    0.992\n",
      "| epoch  19 |   200/  211 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  19 | Time:  8.34s | Train Accuracy    0.993 | Train Loss    0.026 | Valid Accuracy    0.986 | Valid Loss    0.053\n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  20 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  20 |   150/  211 batches | accuracy    0.992\n",
      "| epoch  20 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  20 | Time:  8.35s | Train Accuracy    0.990 | Train Loss    0.025 | Valid Accuracy    0.987 | Valid Loss    0.053\n",
      "-----------------------------------------------------------\n",
      "| epoch  21 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  21 |   100/  211 batches | accuracy    0.993\n",
      "| epoch  21 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  21 |   200/  211 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  21 | Time:  7.98s | Train Accuracy    0.992 | Train Loss    0.023 | Valid Accuracy    0.986 | Valid Loss    0.046\n",
      "-----------------------------------------------------------\n",
      "| epoch  22 |    50/  211 batches | accuracy    0.993\n",
      "| epoch  22 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  22 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  22 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  22 | Time:  7.89s | Train Accuracy    0.994 | Train Loss    0.023 | Valid Accuracy    0.987 | Valid Loss    0.050\n",
      "-----------------------------------------------------------\n",
      "| epoch  23 |    50/  211 batches | accuracy    0.992\n",
      "| epoch  23 |   100/  211 batches | accuracy    0.993\n",
      "| epoch  23 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  23 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  23 | Time:  9.22s | Train Accuracy    0.994 | Train Loss    0.023 | Valid Accuracy    0.987 | Valid Loss    0.048\n",
      "-----------------------------------------------------------\n",
      "| epoch  24 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  24 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  24 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  24 |   200/  211 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  24 | Time:  8.99s | Train Accuracy    0.992 | Train Loss    0.022 | Valid Accuracy    0.987 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  25 |    50/  211 batches | accuracy    0.993\n",
      "| epoch  25 |   100/  211 batches | accuracy    0.993\n",
      "| epoch  25 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  25 |   200/  211 batches | accuracy    0.994\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  25 | Time: 11.82s | Train Accuracy    0.989 | Train Loss    0.020 | Valid Accuracy    0.988 | Valid Loss    0.046\n",
      "-----------------------------------------------------------\n",
      "| epoch  26 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  26 |   100/  211 batches | accuracy    0.993\n",
      "| epoch  26 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  26 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  26 | Time: 12.78s | Train Accuracy    0.995 | Train Loss    0.020 | Valid Accuracy    0.987 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  27 |    50/  211 batches | accuracy    0.993\n",
      "| epoch  27 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  27 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  27 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  27 | Time: 11.55s | Train Accuracy    0.992 | Train Loss    0.020 | Valid Accuracy    0.986 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  28 |    50/  211 batches | accuracy    0.993\n",
      "| epoch  28 |   100/  211 batches | accuracy    0.992\n",
      "| epoch  28 |   150/  211 batches | accuracy    0.994\n",
      "| epoch  28 |   200/  211 batches | accuracy    0.993\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  28 | Time: 13.57s | Train Accuracy    0.995 | Train Loss    0.020 | Valid Accuracy    0.988 | Valid Loss    0.052\n",
      "-----------------------------------------------------------\n",
      "| epoch  29 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  29 |   100/  211 batches | accuracy    0.994\n",
      "| epoch  29 |   150/  211 batches | accuracy    0.994\n",
      "| epoch  29 |   200/  211 batches | accuracy    0.994\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  29 | Time: 11.19s | Train Accuracy    0.993 | Train Loss    0.018 | Valid Accuracy    0.988 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  30 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  30 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  30 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  30 |   200/  211 batches | accuracy    0.994\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  30 | Time: 10.83s | Train Accuracy    0.995 | Train Loss    0.019 | Valid Accuracy    0.986 | Valid Loss    0.059\n",
      "-----------------------------------------------------------\n",
      "| epoch  31 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  31 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  31 |   150/  211 batches | accuracy    0.994\n",
      "| epoch  31 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  31 | Time: 11.17s | Train Accuracy    0.992 | Train Loss    0.018 | Valid Accuracy    0.988 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  32 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  32 |   100/  211 batches | accuracy    0.994\n",
      "| epoch  32 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  32 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  32 | Time: 10.88s | Train Accuracy    0.996 | Train Loss    0.016 | Valid Accuracy    0.989 | Valid Loss    0.053\n",
      "-----------------------------------------------------------\n",
      "| epoch  33 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  33 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  33 |   150/  211 batches | accuracy    0.993\n",
      "| epoch  33 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  33 | Time: 11.73s | Train Accuracy    0.993 | Train Loss    0.017 | Valid Accuracy    0.988 | Valid Loss    0.060\n",
      "-----------------------------------------------------------\n",
      "| epoch  34 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  34 |   100/  211 batches | accuracy    0.994\n",
      "| epoch  34 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  34 |   200/  211 batches | accuracy    0.994\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  34 | Time: 12.97s | Train Accuracy    0.993 | Train Loss    0.018 | Valid Accuracy    0.988 | Valid Loss    0.052\n",
      "-----------------------------------------------------------\n",
      "| epoch  35 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  35 |   100/  211 batches | accuracy    0.994\n",
      "| epoch  35 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  35 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  35 | Time: 11.02s | Train Accuracy    0.994 | Train Loss    0.016 | Valid Accuracy    0.988 | Valid Loss    0.051\n",
      "-----------------------------------------------------------\n",
      "| epoch  36 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  36 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  36 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  36 |   200/  211 batches | accuracy    0.994\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  36 | Time: 11.05s | Train Accuracy    0.992 | Train Loss    0.016 | Valid Accuracy    0.986 | Valid Loss    0.063\n",
      "-----------------------------------------------------------\n",
      "| epoch  37 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  37 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  37 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  37 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  37 | Time: 10.91s | Train Accuracy    0.995 | Train Loss    0.015 | Valid Accuracy    0.990 | Valid Loss    0.052\n",
      "-----------------------------------------------------------\n",
      "| epoch  38 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  38 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  38 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  38 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  38 | Time: 11.37s | Train Accuracy    0.995 | Train Loss    0.015 | Valid Accuracy    0.989 | Valid Loss    0.055\n",
      "-----------------------------------------------------------\n",
      "| epoch  39 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  39 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  39 |   150/  211 batches | accuracy    0.994\n",
      "| epoch  39 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  39 | Time: 11.00s | Train Accuracy    0.993 | Train Loss    0.015 | Valid Accuracy    0.986 | Valid Loss    0.069\n",
      "-----------------------------------------------------------\n",
      "| epoch  40 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  40 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  40 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  40 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  40 | Time: 11.10s | Train Accuracy    0.994 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.061\n",
      "-----------------------------------------------------------\n",
      "| epoch  41 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  41 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  41 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  41 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  41 | Time: 11.32s | Train Accuracy    0.996 | Train Loss    0.013 | Valid Accuracy    0.991 | Valid Loss    0.057\n",
      "-----------------------------------------------------------\n",
      "| epoch  42 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  42 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  42 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  42 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  42 | Time: 11.55s | Train Accuracy    0.995 | Train Loss    0.017 | Valid Accuracy    0.986 | Valid Loss    0.068\n",
      "-----------------------------------------------------------\n",
      "| epoch  43 |    50/  211 batches | accuracy    0.995\n",
      "| epoch  43 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  43 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  43 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  43 | Time: 12.83s | Train Accuracy    0.996 | Train Loss    0.015 | Valid Accuracy    0.988 | Valid Loss    0.066\n",
      "-----------------------------------------------------------\n",
      "| epoch  44 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  44 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  44 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  44 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  44 | Time: 11.30s | Train Accuracy    0.994 | Train Loss    0.013 | Valid Accuracy    0.989 | Valid Loss    0.071\n",
      "-----------------------------------------------------------\n",
      "| epoch  45 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  45 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  45 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  45 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  45 | Time: 12.04s | Train Accuracy    0.994 | Train Loss    0.014 | Valid Accuracy    0.987 | Valid Loss    0.069\n",
      "-----------------------------------------------------------\n",
      "| epoch  46 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  46 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  46 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  46 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  46 | Time: 11.46s | Train Accuracy    0.998 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.069\n",
      "-----------------------------------------------------------\n",
      "| epoch  47 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  47 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  47 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  47 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  47 | Time: 12.78s | Train Accuracy    0.994 | Train Loss    0.012 | Valid Accuracy    0.989 | Valid Loss    0.062\n",
      "-----------------------------------------------------------\n",
      "| epoch  48 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  48 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  48 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  48 |   200/  211 batches | accuracy    0.995\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  48 | Time: 11.15s | Train Accuracy    0.996 | Train Loss    0.013 | Valid Accuracy    0.986 | Valid Loss    0.070\n",
      "-----------------------------------------------------------\n",
      "| epoch  49 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  49 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  49 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  49 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  49 | Time: 12.59s | Train Accuracy    0.996 | Train Loss    0.012 | Valid Accuracy    0.988 | Valid Loss    0.074\n",
      "-----------------------------------------------------------\n",
      "| epoch  50 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  50 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  50 |   150/  211 batches | accuracy    0.995\n",
      "| epoch  50 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  50 | Time: 11.83s | Train Accuracy    0.995 | Train Loss    0.012 | Valid Accuracy    0.989 | Valid Loss    0.070\n",
      "-----------------------------------------------------------\n",
      "| epoch  51 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  51 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  51 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  51 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  51 | Time: 10.75s | Train Accuracy    0.998 | Train Loss    0.011 | Valid Accuracy    0.989 | Valid Loss    0.063\n",
      "-----------------------------------------------------------\n",
      "| epoch  52 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  52 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  52 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  52 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  52 | Time: 11.75s | Train Accuracy    0.994 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.079\n",
      "-----------------------------------------------------------\n",
      "| epoch  53 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  53 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  53 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  53 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  53 | Time: 10.66s | Train Accuracy    0.997 | Train Loss    0.013 | Valid Accuracy    0.988 | Valid Loss    0.079\n",
      "-----------------------------------------------------------\n",
      "| epoch  54 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  54 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  54 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  54 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  54 | Time: 10.99s | Train Accuracy    0.994 | Train Loss    0.011 | Valid Accuracy    0.989 | Valid Loss    0.075\n",
      "-----------------------------------------------------------\n",
      "| epoch  55 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  55 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  55 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  55 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  55 | Time: 10.85s | Train Accuracy    0.994 | Train Loss    0.011 | Valid Accuracy    0.987 | Valid Loss    0.086\n",
      "-----------------------------------------------------------\n",
      "| epoch  56 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  56 |   100/  211 batches | accuracy    0.996\n",
      "| epoch  56 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  56 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  56 | Time: 10.66s | Train Accuracy    0.996 | Train Loss    0.013 | Valid Accuracy    0.987 | Valid Loss    0.074\n",
      "-----------------------------------------------------------\n",
      "| epoch  57 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  57 |   100/  211 batches | accuracy    0.995\n",
      "| epoch  57 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  57 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  57 | Time: 10.85s | Train Accuracy    0.998 | Train Loss    0.013 | Valid Accuracy    0.988 | Valid Loss    0.101\n",
      "-----------------------------------------------------------\n",
      "| epoch  58 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  58 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  58 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  58 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  58 | Time: 10.55s | Train Accuracy    0.999 | Train Loss    0.010 | Valid Accuracy    0.987 | Valid Loss    0.101\n",
      "-----------------------------------------------------------\n",
      "| epoch  59 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  59 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  59 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  59 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  59 | Time: 10.18s | Train Accuracy    0.997 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.082\n",
      "-----------------------------------------------------------\n",
      "| epoch  60 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  60 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  60 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  60 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  60 | Time: 10.37s | Train Accuracy    0.996 | Train Loss    0.009 | Valid Accuracy    0.987 | Valid Loss    0.094\n",
      "-----------------------------------------------------------\n",
      "| epoch  61 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  61 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  61 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  61 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  61 | Time: 10.46s | Train Accuracy    0.993 | Train Loss    0.011 | Valid Accuracy    0.988 | Valid Loss    0.099\n",
      "-----------------------------------------------------------\n",
      "| epoch  62 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  62 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  62 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  62 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  62 | Time: 10.71s | Train Accuracy    0.997 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.086\n",
      "-----------------------------------------------------------\n",
      "| epoch  63 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  63 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  63 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  63 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  63 | Time: 10.54s | Train Accuracy    0.996 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.100\n",
      "-----------------------------------------------------------\n",
      "| epoch  64 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  64 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  64 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  64 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  64 | Time: 10.86s | Train Accuracy    0.996 | Train Loss    0.010 | Valid Accuracy    0.986 | Valid Loss    0.092\n",
      "-----------------------------------------------------------\n",
      "| epoch  65 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  65 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  65 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  65 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  65 | Time: 10.48s | Train Accuracy    0.997 | Train Loss    0.009 | Valid Accuracy    0.989 | Valid Loss    0.089\n",
      "-----------------------------------------------------------\n",
      "| epoch  66 |    50/  211 batches | accuracy    0.996\n",
      "| epoch  66 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  66 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  66 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  66 | Time: 10.79s | Train Accuracy    0.995 | Train Loss    0.010 | Valid Accuracy    0.987 | Valid Loss    0.099\n",
      "-----------------------------------------------------------\n",
      "| epoch  67 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  67 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  67 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  67 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  67 | Time: 11.29s | Train Accuracy    0.996 | Train Loss    0.009 | Valid Accuracy    0.988 | Valid Loss    0.095\n",
      "-----------------------------------------------------------\n",
      "| epoch  68 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  68 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  68 |   150/  211 batches | accuracy    0.996\n",
      "| epoch  68 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  68 | Time: 10.83s | Train Accuracy    0.997 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.116\n",
      "-----------------------------------------------------------\n",
      "| epoch  69 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  69 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  69 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  69 |   200/  211 batches | accuracy    0.996\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  69 | Time: 10.54s | Train Accuracy    0.998 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.107\n",
      "-----------------------------------------------------------\n",
      "| epoch  70 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  70 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  70 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  70 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  70 | Time: 10.45s | Train Accuracy    0.996 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.107\n",
      "-----------------------------------------------------------\n",
      "| epoch  71 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  71 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  71 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  71 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  71 | Time: 10.27s | Train Accuracy    0.998 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.097\n",
      "-----------------------------------------------------------\n",
      "| epoch  72 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  72 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  72 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  72 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  72 | Time: 10.65s | Train Accuracy    0.995 | Train Loss    0.012 | Valid Accuracy    0.988 | Valid Loss    0.107\n",
      "-----------------------------------------------------------\n",
      "| epoch  73 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  73 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  73 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  73 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  73 | Time: 11.15s | Train Accuracy    0.997 | Train Loss    0.009 | Valid Accuracy    0.989 | Valid Loss    0.118\n",
      "-----------------------------------------------------------\n",
      "| epoch  74 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  74 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  74 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  74 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  74 | Time: 10.55s | Train Accuracy    0.998 | Train Loss    0.007 | Valid Accuracy    0.987 | Valid Loss    0.102\n",
      "-----------------------------------------------------------\n",
      "| epoch  75 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  75 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  75 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  75 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  75 | Time: 10.98s | Train Accuracy    0.996 | Train Loss    0.011 | Valid Accuracy    0.987 | Valid Loss    0.109\n",
      "-----------------------------------------------------------\n",
      "| epoch  76 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  76 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  76 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  76 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  76 | Time: 10.48s | Train Accuracy    0.997 | Train Loss    0.012 | Valid Accuracy    0.989 | Valid Loss    0.116\n",
      "-----------------------------------------------------------\n",
      "| epoch  77 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  77 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  77 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  77 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  77 | Time: 10.88s | Train Accuracy    0.997 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.113\n",
      "-----------------------------------------------------------\n",
      "| epoch  78 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  78 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  78 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  78 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  78 | Time: 10.48s | Train Accuracy    0.996 | Train Loss    0.009 | Valid Accuracy    0.986 | Valid Loss    0.120\n",
      "-----------------------------------------------------------\n",
      "| epoch  79 |    50/  211 batches | accuracy    0.999\n",
      "| epoch  79 |   100/  211 batches | accuracy    0.999\n",
      "| epoch  79 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  79 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  79 | Time: 10.68s | Train Accuracy    0.996 | Train Loss    0.007 | Valid Accuracy    0.985 | Valid Loss    0.156\n",
      "-----------------------------------------------------------\n",
      "| epoch  80 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  80 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  80 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  80 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  80 | Time: 11.18s | Train Accuracy    0.997 | Train Loss    0.008 | Valid Accuracy    0.989 | Valid Loss    0.132\n",
      "-----------------------------------------------------------\n",
      "| epoch  81 |    50/  211 batches | accuracy    0.999\n",
      "| epoch  81 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  81 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  81 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  81 | Time: 10.38s | Train Accuracy    0.997 | Train Loss    0.008 | Valid Accuracy    0.988 | Valid Loss    0.109\n",
      "-----------------------------------------------------------\n",
      "| epoch  82 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  82 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  82 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  82 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  82 | Time: 10.61s | Train Accuracy    0.997 | Train Loss    0.010 | Valid Accuracy    0.988 | Valid Loss    0.117\n",
      "-----------------------------------------------------------\n",
      "| epoch  83 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  83 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  83 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  83 |   200/  211 batches | accuracy    0.999\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  83 | Time: 10.39s | Train Accuracy    0.998 | Train Loss    0.008 | Valid Accuracy    0.988 | Valid Loss    0.114\n",
      "-----------------------------------------------------------\n",
      "| epoch  84 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  84 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  84 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  84 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  84 | Time: 10.47s | Train Accuracy    0.999 | Train Loss    0.009 | Valid Accuracy    0.989 | Valid Loss    0.126\n",
      "-----------------------------------------------------------\n",
      "| epoch  85 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  85 |   100/  211 batches | accuracy    0.999\n",
      "| epoch  85 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  85 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  85 | Time: 10.44s | Train Accuracy    0.998 | Train Loss    0.008 | Valid Accuracy    0.988 | Valid Loss    0.136\n",
      "-----------------------------------------------------------\n",
      "| epoch  86 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  86 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  86 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  86 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  86 | Time: 10.12s | Train Accuracy    0.996 | Train Loss    0.010 | Valid Accuracy    0.986 | Valid Loss    0.128\n",
      "-----------------------------------------------------------\n",
      "| epoch  87 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  87 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  87 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  87 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  87 | Time: 10.19s | Train Accuracy    0.996 | Train Loss    0.010 | Valid Accuracy    0.989 | Valid Loss    0.120\n",
      "-----------------------------------------------------------\n",
      "| epoch  88 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  88 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  88 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  88 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  88 | Time: 10.35s | Train Accuracy    0.999 | Train Loss    0.010 | Valid Accuracy    0.989 | Valid Loss    0.114\n",
      "-----------------------------------------------------------\n",
      "| epoch  89 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  89 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  89 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  89 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  89 | Time: 10.14s | Train Accuracy    0.997 | Train Loss    0.010 | Valid Accuracy    0.989 | Valid Loss    0.145\n",
      "-----------------------------------------------------------\n",
      "| epoch  90 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  90 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  90 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  90 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  90 | Time: 10.45s | Train Accuracy    0.997 | Train Loss    0.013 | Valid Accuracy    0.988 | Valid Loss    0.129\n",
      "-----------------------------------------------------------\n",
      "| epoch  91 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  91 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  91 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  91 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  91 | Time: 10.56s | Train Accuracy    0.998 | Train Loss    0.008 | Valid Accuracy    0.987 | Valid Loss    0.126\n",
      "-----------------------------------------------------------\n",
      "| epoch  92 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  92 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  92 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  92 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  92 | Time: 10.41s | Train Accuracy    0.995 | Train Loss    0.010 | Valid Accuracy    0.989 | Valid Loss    0.125\n",
      "-----------------------------------------------------------\n",
      "| epoch  93 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  93 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  93 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  93 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  93 | Time: 10.61s | Train Accuracy    0.996 | Train Loss    0.009 | Valid Accuracy    0.989 | Valid Loss    0.128\n",
      "-----------------------------------------------------------\n",
      "| epoch  94 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  94 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  94 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  94 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  94 | Time: 10.52s | Train Accuracy    0.994 | Train Loss    0.012 | Valid Accuracy    0.987 | Valid Loss    0.150\n",
      "-----------------------------------------------------------\n",
      "| epoch  95 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  95 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  95 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  95 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  95 | Time: 10.20s | Train Accuracy    0.998 | Train Loss    0.008 | Valid Accuracy    0.989 | Valid Loss    0.120\n",
      "-----------------------------------------------------------\n",
      "| epoch  96 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  96 |   100/  211 batches | accuracy    0.999\n",
      "| epoch  96 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  96 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  96 | Time: 10.45s | Train Accuracy    0.996 | Train Loss    0.008 | Valid Accuracy    0.985 | Valid Loss    0.167\n",
      "-----------------------------------------------------------\n",
      "| epoch  97 |    50/  211 batches | accuracy    0.997\n",
      "| epoch  97 |   100/  211 batches | accuracy    0.997\n",
      "| epoch  97 |   150/  211 batches | accuracy    0.997\n",
      "| epoch  97 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  97 | Time: 10.28s | Train Accuracy    0.997 | Train Loss    0.010 | Valid Accuracy    0.986 | Valid Loss    0.159\n",
      "-----------------------------------------------------------\n",
      "| epoch  98 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  98 |   100/  211 batches | accuracy    0.998\n",
      "| epoch  98 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  98 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  98 | Time: 10.33s | Train Accuracy    0.998 | Train Loss    0.008 | Valid Accuracy    0.987 | Valid Loss    0.155\n",
      "-----------------------------------------------------------\n",
      "| epoch  99 |    50/  211 batches | accuracy    0.998\n",
      "| epoch  99 |   100/  211 batches | accuracy    0.999\n",
      "| epoch  99 |   150/  211 batches | accuracy    0.998\n",
      "| epoch  99 |   200/  211 batches | accuracy    0.998\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  99 | Time: 10.81s | Train Accuracy    0.999 | Train Loss    0.006 | Valid Accuracy    0.989 | Valid Loss    0.151\n",
      "-----------------------------------------------------------\n",
      "| epoch 100 |    50/  211 batches | accuracy    0.998\n",
      "| epoch 100 |   100/  211 batches | accuracy    0.998\n",
      "| epoch 100 |   150/  211 batches | accuracy    0.999\n",
      "| epoch 100 |   200/  211 batches | accuracy    0.997\n",
      "-----------------------------------------------------------\n",
      "| End of epoch 100 | Time: 10.79s | Train Accuracy    0.997 | Train Loss    0.008 | Valid Accuracy    0.987 | Valid Loss    0.157\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\AppData\\Local\\Temp\\ipykernel_12632\\190128675.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNetClassifier(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc_1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_data.dataset.classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lenet_model = LeNetClassifier(num_classes)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet_model.parameters())\n",
    "\n",
    "num_epochs = 100\n",
    "save_model = './model'\n",
    "\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "eval_accs = []\n",
    "eval_losses = []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_acc, train_loss = train(lenet_model, optimizer, criterion, train_dataloader, device, epoch)\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_acc, eval_loss = evaluate(lenet_model, criterion, valid_dataloader, device)\n",
    "    eval_accs.append(eval_acc)\n",
    "    eval_losses.append(eval_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if eval_loss < best_loss_eval:\n",
    "        torch.save(lenet_model.state_dict(), save_model + '/lenet_model.pt')\n",
    "    \n",
    "    # Print loss, accuracy at the end of the epoch\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f}\".format(\n",
    "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "# Load best model\n",
    "lenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n",
    "lenet_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.986\n",
      "Test Loss: 0.140\n"
     ]
    }
   ],
   "source": [
    "# Gn php bin i (transforms) cho test_data\n",
    "test_data.transform = test_transforms\n",
    "\n",
    "# To DataLoader cho tp test\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# nh gi m hnh trn tp test\n",
    "test_acc, test_loss = evaluate(lenet_model, criterion, test_dataloader, device)\n",
    "\n",
    "# In kt qu  chnh xc (accuracy) v mt mt (loss) trn tp test\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(f\"Test Loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ly ngu nhin 10 hnh nh t tp test\n",
    "num_samples = 10\n",
    "indices = random.sample(range(len(test_data)), num_samples)\n",
    "samples = torch.stack([test_data[i][0] for i in indices])  # Ly d liu hnh nh\n",
    "labels = [test_data[i][1] for i in indices]               # Ly nhn thc t\n",
    "\n",
    "# Chuyn hnh nh sang thit b\n",
    "samples = samples.to(device)\n",
    "\n",
    "# D on bng m hnh\n",
    "lenet_model.eval()  # t m hnh  ch  nh gi (evaluation)\n",
    "with torch.no_grad():  # Tt tnh ton gradient  tng tc\n",
    "    predictions = lenet_model(samples)\n",
    "    predicted_labels = predictions.argmax(1).cpu().numpy()  # Ly nhn d on\n",
    "\n",
    "# V hnh v in ra kt qu d on\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(samples[i].cpu().squeeze(), cmap='gray')  # Hin th hnh nh\n",
    "    plt.title(f\"True: {labels[i]} Pred: {predicted_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
